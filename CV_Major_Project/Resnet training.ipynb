{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8251040,"sourceType":"datasetVersion","datasetId":4895767}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nimport numpy as np\nfrom sklearn.metrics import classification_report, roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:04:23.970999Z","iopub.execute_input":"2024-04-28T09:04:23.971632Z","iopub.status.idle":"2024-04-28T09:04:23.976843Z","shell.execute_reply.started":"2024-04-28T09:04:23.971599Z","shell.execute_reply":"2024-04-28T09:04:23.975936Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImageFolder(\"/kaggle/input/cv-dataset-2/data_folder/train\",transform=ToTensor())\ntest_dataset = ImageFolder(\"/kaggle/input/cv-dataset-2/data_folder/test\",transform=ToTensor())","metadata":{"execution":{"iopub.status.busy":"2024-04-28T08:31:46.519562Z","iopub.execute_input":"2024-04-28T08:31:46.520320Z","iopub.status.idle":"2024-04-28T08:31:49.340928Z","shell.execute_reply.started":"2024-04-28T08:31:46.520284Z","shell.execute_reply":"2024-04-28T08:31:49.340149Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T08:31:49.341923Z","iopub.execute_input":"2024-04-28T08:31:49.342175Z","iopub.status.idle":"2024-04-28T08:31:49.348406Z","shell.execute_reply.started":"2024-04-28T08:31:49.342153Z","shell.execute_reply":"2024-04-28T08:31:49.347556Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel = resnet18(num_classes=2).to(device)\nvalue_to_prob = nn.Softmax(dim=1).to(device)\nopt = optim.Adam(model.parameters(),lr=1e-4)\nloss_fn = nn.CrossEntropyLoss()\nmin_loss = np.inf\nfor epoch in range(100):\n    train_losses = []\n    for X, Y in train_dataloader:\n        X = X.to(device)\n        Y = Y.to(device)\n        opt.zero_grad()\n        prob = value_to_prob(model(X))\n        loss = loss_fn(prob, Y)\n        loss.backward()\n        opt.step()\n        train_losses.append(loss.item())\n    test_losses = []\n    with torch.no_grad():\n        for X, Y in test_dataloader:\n            X = X.to(device)\n            Y = Y.to(device)\n            prob = value_to_prob(model(X))\n            loss = loss_fn(prob, Y)\n            test_losses.append(loss.item())\n    train_loss = np.mean(train_losses)\n    test_loss = np.mean(test_losses)\n    print(f\"epoch {epoch}/100\\ttrain : {train_loss:.6f}\\ttest : {test_loss:.6f}\")\n    if test_loss < min_loss:\n        min_loss = test_loss\n        torch.save(model.state_dict(),\"best_model.pt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-28T08:31:49.350232Z","iopub.execute_input":"2024-04-28T08:31:49.350495Z","iopub.status.idle":"2024-04-28T08:47:26.199879Z","shell.execute_reply.started":"2024-04-28T08:31:49.350472Z","shell.execute_reply":"2024-04-28T08:47:26.198876Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"epoch 0/100\ttrain : 0.401383\ttest : 0.714335\nepoch 1/100\ttrain : 0.330702\ttest : 0.729753\nepoch 2/100\ttrain : 0.319732\ttest : 0.694247\nepoch 3/100\ttrain : 0.316455\ttest : 0.701846\nepoch 4/100\ttrain : 0.316426\ttest : 0.695879\nepoch 5/100\ttrain : 0.315218\ttest : 0.698672\nepoch 6/100\ttrain : 0.315414\ttest : 0.693790\nepoch 7/100\ttrain : 0.314937\ttest : 0.689087\nepoch 8/100\ttrain : 0.315516\ttest : 0.689351\nepoch 9/100\ttrain : 0.315921\ttest : 0.678612\nepoch 10/100\ttrain : 0.315329\ttest : 0.679529\nepoch 11/100\ttrain : 0.314978\ttest : 0.670869\nepoch 12/100\ttrain : 0.314924\ttest : 0.659261\nepoch 13/100\ttrain : 0.314756\ttest : 0.672492\nepoch 14/100\ttrain : 0.314577\ttest : 0.638569\nepoch 15/100\ttrain : 0.314459\ttest : 0.648977\nepoch 16/100\ttrain : 0.314494\ttest : 0.656884\nepoch 17/100\ttrain : 0.314199\ttest : 0.636348\nepoch 18/100\ttrain : 0.313658\ttest : 0.642864\nepoch 19/100\ttrain : 0.314472\ttest : 0.635452\nepoch 20/100\ttrain : 0.313977\ttest : 0.644575\nepoch 21/100\ttrain : 0.313823\ttest : 0.641170\nepoch 22/100\ttrain : 0.314044\ttest : 0.636697\nepoch 23/100\ttrain : 0.313731\ttest : 0.628262\nepoch 24/100\ttrain : 0.313574\ttest : 0.622747\nepoch 25/100\ttrain : 0.313554\ttest : 0.618861\nepoch 26/100\ttrain : 0.313549\ttest : 0.617404\nepoch 27/100\ttrain : 0.313807\ttest : 0.616629\nepoch 28/100\ttrain : 0.313531\ttest : 0.621480\nepoch 29/100\ttrain : 0.313530\ttest : 0.619249\nepoch 30/100\ttrain : 0.313519\ttest : 0.617975\nepoch 31/100\ttrain : 0.313518\ttest : 0.617785\nepoch 32/100\ttrain : 0.313520\ttest : 0.616147\nepoch 33/100\ttrain : 0.313519\ttest : 0.616533\nepoch 34/100\ttrain : 0.313523\ttest : 0.617372\nepoch 35/100\ttrain : 0.313515\ttest : 0.616511\nepoch 36/100\ttrain : 0.313513\ttest : 0.615868\nepoch 37/100\ttrain : 0.313525\ttest : 0.613623\nepoch 38/100\ttrain : 0.313516\ttest : 0.612654\nepoch 39/100\ttrain : 0.313513\ttest : 0.612464\nepoch 40/100\ttrain : 0.313514\ttest : 0.611973\nepoch 41/100\ttrain : 0.313515\ttest : 0.612106\nepoch 42/100\ttrain : 0.313515\ttest : 0.611344\nepoch 43/100\ttrain : 0.313517\ttest : 0.610798\nepoch 44/100\ttrain : 0.313513\ttest : 0.610571\nepoch 45/100\ttrain : 0.313519\ttest : 0.604580\nepoch 46/100\ttrain : 0.313907\ttest : 0.635979\nepoch 47/100\ttrain : 0.320671\ttest : 0.625025\nepoch 48/100\ttrain : 0.320941\ttest : 0.614627\nepoch 49/100\ttrain : 0.316112\ttest : 0.590158\nepoch 50/100\ttrain : 0.316824\ttest : 0.611181\nepoch 51/100\ttrain : 0.316084\ttest : 0.602109\nepoch 52/100\ttrain : 0.315902\ttest : 0.546518\nepoch 53/100\ttrain : 0.314560\ttest : 0.549578\nepoch 54/100\ttrain : 0.314266\ttest : 0.536978\nepoch 55/100\ttrain : 0.313633\ttest : 0.548065\nepoch 56/100\ttrain : 0.313650\ttest : 0.549634\nepoch 57/100\ttrain : 0.313533\ttest : 0.556235\nepoch 58/100\ttrain : 0.313910\ttest : 0.573128\nepoch 59/100\ttrain : 0.314590\ttest : 0.573662\nepoch 60/100\ttrain : 0.314448\ttest : 0.560278\nepoch 61/100\ttrain : 0.313896\ttest : 0.555070\nepoch 62/100\ttrain : 0.313581\ttest : 0.556458\nepoch 63/100\ttrain : 0.313530\ttest : 0.548733\nepoch 64/100\ttrain : 0.313519\ttest : 0.546460\nepoch 65/100\ttrain : 0.313519\ttest : 0.544426\nepoch 66/100\ttrain : 0.313518\ttest : 0.543125\nepoch 67/100\ttrain : 0.313523\ttest : 0.538922\nepoch 68/100\ttrain : 0.313514\ttest : 0.537853\nepoch 69/100\ttrain : 0.313513\ttest : 0.537463\nepoch 70/100\ttrain : 0.313516\ttest : 0.536103\nepoch 71/100\ttrain : 0.313516\ttest : 0.535198\nepoch 72/100\ttrain : 0.313513\ttest : 0.534474\nepoch 73/100\ttrain : 0.313513\ttest : 0.533932\nepoch 74/100\ttrain : 0.313515\ttest : 0.532536\nepoch 75/100\ttrain : 0.313513\ttest : 0.531930\nepoch 76/100\ttrain : 0.313512\ttest : 0.531030\nepoch 77/100\ttrain : 0.313516\ttest : 0.530428\nepoch 78/100\ttrain : 0.313513\ttest : 0.529998\nepoch 79/100\ttrain : 0.313512\ttest : 0.529396\nepoch 80/100\ttrain : 0.313513\ttest : 0.528619\nepoch 81/100\ttrain : 0.313511\ttest : 0.528388\nepoch 82/100\ttrain : 0.313512\ttest : 0.527897\nepoch 83/100\ttrain : 0.313514\ttest : 0.528838\nepoch 84/100\ttrain : 0.313511\ttest : 0.528329\nepoch 85/100\ttrain : 0.313511\ttest : 0.527929\nepoch 86/100\ttrain : 0.313512\ttest : 0.527038\nepoch 87/100\ttrain : 0.313511\ttest : 0.526592\nepoch 88/100\ttrain : 0.313512\ttest : 0.525294\nepoch 89/100\ttrain : 0.313511\ttest : 0.524947\nepoch 90/100\ttrain : 0.313511\ttest : 0.524378\nepoch 91/100\ttrain : 0.313511\ttest : 0.524028\nepoch 92/100\ttrain : 0.313513\ttest : 0.523029\nepoch 93/100\ttrain : 0.313513\ttest : 0.522466\nepoch 94/100\ttrain : 0.313512\ttest : 0.520225\nepoch 95/100\ttrain : 0.313512\ttest : 0.519371\nepoch 96/100\ttrain : 0.313512\ttest : 0.518617\nepoch 97/100\ttrain : 0.313511\ttest : 0.518293\nepoch 98/100\ttrain : 0.313511\ttest : 0.517931\nepoch 99/100\ttrain : 0.313511\ttest : 0.517630\n","output_type":"stream"}]},{"cell_type":"code","source":"true_y = []\nprob_y = []\nwith torch.no_grad():\n    for X, Y in test_dataloader:\n        X = X.to(device)\n        prob = value_to_prob(model(X))\n        true_y.append(Y.numpy())\n        prob_y.append(prob.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2024-04-28T08:59:47.624799Z","iopub.execute_input":"2024-04-28T08:59:47.625170Z","iopub.status.idle":"2024-04-28T08:59:49.908531Z","shell.execute_reply.started":"2024-04-28T08:59:47.625138Z","shell.execute_reply":"2024-04-28T08:59:49.907696Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"prob_y = np.concatenate(prob_y)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:02:39.464808Z","iopub.execute_input":"2024-04-28T09:02:39.465627Z","iopub.status.idle":"2024-04-28T09:02:39.469999Z","shell.execute_reply.started":"2024-04-28T09:02:39.465594Z","shell.execute_reply":"2024-04-28T09:02:39.469066Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"true_y = np.concatenate(true_y)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:02:58.278778Z","iopub.execute_input":"2024-04-28T09:02:58.279680Z","iopub.status.idle":"2024-04-28T09:02:58.283866Z","shell.execute_reply.started":"2024-04-28T09:02:58.279646Z","shell.execute_reply":"2024-04-28T09:02:58.282932Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pred_y = np.argmax(prob_y,axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:03:37.835863Z","iopub.execute_input":"2024-04-28T09:03:37.836292Z","iopub.status.idle":"2024-04-28T09:03:37.841066Z","shell.execute_reply.started":"2024-04-28T09:03:37.836260Z","shell.execute_reply":"2024-04-28T09:03:37.840207Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"pred_y","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:03:42.731842Z","iopub.execute_input":"2024-04-28T09:03:42.732894Z","iopub.status.idle":"2024-04-28T09:03:42.741793Z","shell.execute_reply.started":"2024-04-28T09:03:42.732859Z","shell.execute_reply":"2024-04-28T09:03:42.740857Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n       1, 1, 1, 0, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"print(classification_report(true_y,pred_y))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:04:41.472065Z","iopub.execute_input":"2024-04-28T09:04:41.472745Z","iopub.status.idle":"2024-04-28T09:04:41.489217Z","shell.execute_reply.started":"2024-04-28T09:04:41.472710Z","shell.execute_reply":"2024-04-28T09:04:41.488385Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.81      0.77      0.79       500\n           1       0.78      0.82      0.80       500\n\n    accuracy                           0.79      1000\n   macro avg       0.79      0.79      0.79      1000\nweighted avg       0.79      0.79      0.79      1000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"roc_auc_score(true_y,prob_y[:,1])","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:05:31.414158Z","iopub.execute_input":"2024-04-28T09:05:31.414549Z","iopub.status.idle":"2024-04-28T09:05:31.424569Z","shell.execute_reply.started":"2024-04-28T09:05:31.414518Z","shell.execute_reply":"2024-04-28T09:05:31.423484Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.784052"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}